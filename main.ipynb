{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldacosta/miniconda3/envs/work/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 1.31k/1.31k [00:00<00:00, 5.48MB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 999k/999k [00:00<00:00, 7.76MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 4.06MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 957/957 [00:00<00:00, 2.46MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.83k/1.83k [00:00<00:00, 5.40MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 558M/558M [00:56<00:00, 9.90MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hallisky/bart-base-nontoxic-expert\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"hallisky/bart-base-nontoxic-expert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/transformers/perplexity.html\n",
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/gscratch/xlab/hallisky/KAug/cache\"\n",
    "import transformers\n",
    "import torch\n",
    "from IPython import embed\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_perplexity(sentences, model = None, tokenizer = None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if tokenizer is None or model is None:\n",
    "        model_id = 'gpt2-xl'\n",
    "        model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "        tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
    "    model.eval()\n",
    "    perp = []\n",
    "    for sentence in tqdm(sentences):\n",
    "        tokenized = tokenizer(sentence, return_tensors = \"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(tokenized[\"input_ids\"], labels=tokenized[\"input_ids\"])\n",
    "        \n",
    "        final_perp = math.exp(output.loss.item())\n",
    "        if final_perp < 1e4:\n",
    "            perp.append(final_perp)\n",
    "    return perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 689/689 [00:00<00:00, 2.60MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 6.43G/6.43G [12:21<00:00, 8.68MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 116kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 4.17MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 2.43MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 12.2MB/s]\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.490842726376176, 853.9251959708315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_perplexity([\"Hey man! How are you doing? It's been a really long time hasn't it\", \"gihasb?? d as  s s a  \"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.490842726376176, 853.9251959708315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_perplexity([\"Hey man! How are you doing? It's been a really long time hasn't it\", \"gihasb?? d as  s s a  \"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import embed\n",
    "import json \n",
    "import requests \n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from googleapiclient import discovery\n",
    "\n",
    "# Use perspective API\n",
    "qps = 10\n",
    "rate = 1/qps\n",
    "\n",
    "# PUT YOUR API KEY HERE\n",
    "api_key = \"AIzaSyAVytlgvLYmAM1w-gy57obAoRsjGfcSHoE\"\n",
    "\n",
    "def getAttribProb(attrib_name, response_dict):\n",
    "    return response_dict['attributeScores'][attrib_name]['summaryScore']['value']\n",
    "\n",
    "def _make_request(text: str, service):\n",
    "    analyze_request = {\n",
    "        'comment': {'text': text},\n",
    "        'languages': ['en'],\n",
    "        'requestedAttributes':  {'TOXICITY': {}, 'IDENTITY_ATTACK': {}, 'INSULT': {}}\n",
    "    }\n",
    "    return service.comments().analyze(body=analyze_request)\n",
    "\n",
    "def getAttribs(request):\n",
    "    response = requests.post(url=url, data=request) \n",
    "    return response\n",
    "\n",
    "def getAttribsBatch(sents):\n",
    "    return [getAttribs(s) for s in sents]\n",
    "\n",
    "def postprocess(response):\n",
    "    response_dict = json.loads(response.content) \n",
    "   #  print(response_dict)\n",
    "    return getAttribProb(\"TOXICITY\", response_dict)\n",
    "\n",
    "def get_toxicity(texts):\n",
    "    old_len = len(texts)\n",
    "    texts = list(filter(lambda x: len(x.strip()) > 0, texts))\n",
    "    new_len = len(texts)\n",
    "    print(\"Filtered\", new_len, \"texts from\", old_len, \"originally\")\n",
    "    \n",
    "    service = discovery.build('comments:analyze', 'v1alpha1',\n",
    "                               discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "                               developerKey=api_key,\n",
    "                               static_discovery=False)\n",
    "\n",
    "    # Make API request\n",
    "    stop_lim = range(0, len(texts), qps)[-1]\n",
    "    all_outputs = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), qps)):   \n",
    "        batch_request = service.new_batch_http_request() \n",
    "        start = time.time()\n",
    "        # Keys guaranteed in insertion order (Python 3.7+)\n",
    "        responses = {str(uid): None for uid in range(min(qps, len(texts) - i))}\n",
    "        all_keys = list(responses.keys())\n",
    "        def response_callback(request_id, response, exception):\n",
    "            nonlocal responses\n",
    "            responses[request_id] = (response, exception)\n",
    "\n",
    "        for uid, text in zip(list(all_keys),texts[i:i+qps]):\n",
    "            batch_request.add(_make_request(text, service), callback=response_callback, request_id=uid)\n",
    "        batch_request.execute()\n",
    "        \n",
    "        all_outputs.extend(list(responses.values()))\n",
    "        if i != stop_lim:\n",
    "            end = time.time()\n",
    "            if (start - end) < 1:\n",
    "                time.sleep(1 - (start - end))\n",
    "    return [j[0][\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"] for j in all_outputs] # + [0] * (new_len - old_len)\n",
    "    # return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 300 texts from 300 originally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:42<00:00,  1.43s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Some examples of toxicity scores on text\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m temp \u001b[39m=\u001b[39m get_toxicity([\u001b[39m\"\u001b[39;49m\u001b[39mShe\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms Mexican, she can be our maid.\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mShe\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms so smart, she can be our best friend.\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mShe\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms our president, she can be our president.\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m*\u001b[39;49m \u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb Cell 8\u001b[0m line \u001b[0;36mget_toxicity\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X25sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         \u001b[39mif\u001b[39;00m (start \u001b[39m-\u001b[39m end) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X25sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m             time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m (start \u001b[39m-\u001b[39m end))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X25sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [j[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mattributeScores\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mTOXICITY\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msummaryScore\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m all_outputs]\n",
      "\u001b[1;32m/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb Cell 8\u001b[0m line \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X25sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         \u001b[39mif\u001b[39;00m (start \u001b[39m-\u001b[39m end) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X25sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m             time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m (start \u001b[39m-\u001b[39m end))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X25sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [j[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mattributeScores\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39m\u001b[39mTOXICITY\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msummaryScore\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m all_outputs]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Some examples of toxicity scores on text\n",
    "temp = get_toxicity([\"She's Mexican, she can be our maid.\", \"She's so smart, she can be our best friend.\", \"She's our president, she can be our president.\"])\n",
    "# get_toxicity([\"I don't like short hair on girls.\", \"I don't like short skirts on girls.\"])\n",
    "# embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 2 texts from 2 originally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0,\n",
       "       'end': 33,\n",
       "       'score': {'value': 0.30716252, 'type': 'PROBABILITY'}}],\n",
       "     'summaryScore': {'value': 0.30716252, 'type': 'PROBABILITY'}},\n",
       "    'INSULT': {'spanScores': [{'begin': 0,\n",
       "       'end': 33,\n",
       "       'score': {'value': 0.0838533, 'type': 'PROBABILITY'}}],\n",
       "     'summaryScore': {'value': 0.0838533, 'type': 'PROBABILITY'}},\n",
       "    'IDENTITY_ATTACK': {'spanScores': [{'begin': 0,\n",
       "       'end': 33,\n",
       "       'score': {'value': 0.28883415, 'type': 'PROBABILITY'}}],\n",
       "     'summaryScore': {'value': 0.28883415, 'type': 'PROBABILITY'}}},\n",
       "   'languages': ['en'],\n",
       "   'detectedLanguages': ['en']},\n",
       "  None),\n",
       " ({'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0,\n",
       "       'end': 35,\n",
       "       'score': {'value': 0.2854869, 'type': 'PROBABILITY'}}],\n",
       "     'summaryScore': {'value': 0.2854869, 'type': 'PROBABILITY'}},\n",
       "    'IDENTITY_ATTACK': {'spanScores': [{'begin': 0,\n",
       "       'end': 35,\n",
       "       'score': {'value': 0.28034934, 'type': 'PROBABILITY'}}],\n",
       "     'summaryScore': {'value': 0.28034934, 'type': 'PROBABILITY'}},\n",
       "    'INSULT': {'spanScores': [{'begin': 0,\n",
       "       'end': 35,\n",
       "       'score': {'value': 0.07301756, 'type': 'PROBABILITY'}}],\n",
       "     'summaryScore': {'value': 0.07301756, 'type': 'PROBABILITY'}}},\n",
       "   'languages': ['en'],\n",
       "   'detectedLanguages': ['en']},\n",
       "  None)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_toxicity([\"I don't like short hair on girls.\", \"I don't like short skirts on girls.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_scores(evaluation_dataset, lang = 'en', id = None):\n",
    "    bert_metric = datasets.load_metric('bertscore', experiment_id = id)\n",
    "    for model_input, gold_references in evaluation_dataset:\n",
    "        bert_metric.add_batch(predictions=[model_input], references=[gold_references])\n",
    "\n",
    "    final_score = bert_metric.compute(lang = lang)\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datasets' has no attribute 'load_metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb Cell 10\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_bert_scores([predictions, references])\n",
      "\u001b[1;32m/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb Cell 10\u001b[0m line \u001b[0;36mget_bert_scores\u001b[0;34m(evaluation_dataset, lang, id)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_bert_scores\u001b[39m(evaluation_dataset, lang \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39men\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     bert_metric \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mload_metric(\u001b[39m'\u001b[39m\u001b[39mbertscore\u001b[39m\u001b[39m'\u001b[39m, experiment_id \u001b[39m=\u001b[39m \u001b[39mid\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m model_input, gold_references \u001b[39min\u001b[39;00m evaluation_dataset:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/csci662/Project/MarcoDetoxification/main.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         bert_metric\u001b[39m.\u001b[39madd_batch(predictions\u001b[39m=\u001b[39m[model_input], references\u001b[39m=\u001b[39m[gold_references])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'datasets' has no attribute 'load_metric'"
     ]
    }
   ],
   "source": [
    "get_bert_scores([predictions, references])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bleu Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sacrebleu.metrics import BLEU\n",
    "# from IPython import embed\n",
    "# from nltk.translate.bleu_score import sentence_bleu\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def get_bleu(references,hypotheses):\n",
    "#     bleu = BLEU()\n",
    "#     return bleu.corpus_score(hypotheses, references).score\n",
    "\n",
    "# def calc_bleu(inputs, preds):\n",
    "#     bleu_sim = 0\n",
    "#     counter = 0\n",
    "#     for i in tqdm(range(len(inputs))):\n",
    "#         if len(inputs[i]) > 3 and len(preds[i]) > 3:\n",
    "#             bleu_sim += sentence_bleu([inputs[i]], preds[i])\n",
    "#             counter += 1\n",
    "#     return float(bleu_sim / counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
