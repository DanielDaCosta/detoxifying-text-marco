# Dataset

# Training
Jigsaw dataset, split into toxic and non-toxic subsets. Toxic subset consists of data where >0.5 proportion of annotators rated toxic, while non-toxic subset consists of data where 0 proportion of annotators rated toxic. `split_dataset_code.ipynb` split the raw dataset into toxic and non-toxic data.

**Raw Dataset**
- https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/data?select=train.csv

**Splitted dataset**
- https://drive.google.com/drive/folders/1TeUC1swuEIScsIzI2Cnl28Yg3fF8vfzi

# Evaluation

Location: https://drive.google.com/drive/folders/1gr8sNuVJGfRygbsw0p9LjlTihuTBqkRb?usp=drive_link

### <ins> DynaBench </ins>

Contains the data from the full DynaHate paper (last round) and located under `dynabench` #TODO look into more details of this

### <ins> Microagressions.com</ins>

Contains data from [microaggressions.com](microaggressions.com), a Tumblr blog of self-reported microaggressions "in the wild". Located under `micoagressions`

### <ins> Social Bias Frames </ins>

Contains data from social bias frames (todo, link), specifically the microaggression portion. Located under `sbf`.