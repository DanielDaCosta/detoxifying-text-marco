{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/data?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "toxicity_individual_annotations = pd.read_csv(\"toxicity_individual_annotations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging train data with toxicity_individual_annotations.csv - The individual rater decisions for toxicity questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_individual_annotations_agg = toxicity_individual_annotations.groupby('id').agg(\n",
    "    total_n_workers=('worker', 'count'),\n",
    "    toxic_sum=('toxic', 'sum')\n",
    ").reset_index()\n",
    "toxicity_individual_annotations_agg['pct_toxic'] =\\\n",
    "    (toxicity_individual_annotations_agg['toxic_sum']/toxicity_individual_annotations_agg['total_n_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[train['comment_text'] == 'The ideology of Islam is in direct conflict with the constitution on many counts. It is unconstitutional to let muslims into the US.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toxicity_individual_annotations[toxicity_individual_annotations[\"id\"] == 917315]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_label = train.merge(toxicity_individual_annotations_agg, how='inner', on=\"id\")\n",
    "# test_with_label = test.merge(toxicity_individual_annotations_agg, how='inner', on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any inconsistency on merge\n",
    "assert train.shape[0] == train_with_label[~train_with_label['pct_toxic'].isnull()].shape[0]\n",
    "# assert test.shape[0] == test_with_label[~test_with_label['pct_toxic'].isnull()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split on Toxic and Non-Toxic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_toxic = train_with_label[train_with_label['pct_toxic'] >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_non_toxic = train_with_label[train_with_label['pct_toxic'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144334"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_toxic.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1264764"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_non_toxic.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train/Val Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2017404076655535\n",
    "val_n = int(val_size * len(train_toxic))\n",
    "val_n_non_toxic = int(val_size * len(train_non_toxic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toxic\n",
    "val_toxic = train_toxic.sample(n=val_n, random_state=seed)\n",
    "train_toxic_final = train_toxic.drop(val_toxic.index)\n",
    "\n",
    "# Non-Toxic\n",
    "val_non_toxic = train_non_toxic.sample(n=val_n_non_toxic, random_state=seed)\n",
    "train_non_toxic_final = train_non_toxic.drop(val_non_toxic.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_toxic.shape[0] == train_toxic_final.shape[0] + val_toxic.shape[0]\n",
    "assert train_non_toxic.shape[0] == train_non_toxic_final.shape[0] + val_non_toxic.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39853</th>\n",
       "      <td>Well, maybe social media will give justice kee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835139</th>\n",
       "      <td>You are correct...the world would be better of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560255</th>\n",
       "      <td>I'd like to see a ban on Trump entering countr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922719</th>\n",
       "      <td>So typical of republicans. They love to lock p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146379</th>\n",
       "      <td>Classic Useful idiot of the Red kind! They jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487884</th>\n",
       "      <td>All you nay-sayers (sp) do you also think that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962764</th>\n",
       "      <td>.\\n\\n\"The Pope gave Mr. Trump ..... Laudato si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154039</th>\n",
       "      <td>There is not reasoning with someone who sympat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894440</th>\n",
       "      <td>Shades of Don Young! Jeez, guess it wasn't rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926772</th>\n",
       "      <td>Man, that really sucks. Get a \"real\" job in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29118 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment_text\n",
       "39853    Well, maybe social media will give justice kee...\n",
       "835139   You are correct...the world would be better of...\n",
       "560255   I'd like to see a ban on Trump entering countr...\n",
       "922719   So typical of republicans. They love to lock p...\n",
       "146379   Classic Useful idiot of the Red kind! They jus...\n",
       "...                                                    ...\n",
       "1487884  All you nay-sayers (sp) do you also think that...\n",
       "962764   .\\n\\n\"The Pope gave Mr. Trump ..... Laudato si...\n",
       "1154039  There is not reasoning with someone who sympat...\n",
       "894440   Shades of Don Young! Jeez, guess it wasn't rea...\n",
       "926772   Man, that really sucks. Get a \"real\" job in th...\n",
       "\n",
       "[29118 rows x 1 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_toxic[['comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_toxic[['comment_text']].to_csv(\"../detoxifying-text-marco/datasets/val_toxic.csv\", index=False)\n",
    "train_toxic_final[['comment_text']].to_csv(\"../detoxifying-text-marco/datasets/train_toxic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_non_toxic[['comment_text']].to_csv(\"../detoxifying-text-marco/datasets/val_non_toxic.csv\", index=False)\n",
    "train_non_toxic_final[['comment_text']].to_csv(\"../detoxifying-text-marco/datasets/train_non_toxic.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
